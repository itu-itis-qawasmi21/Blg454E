{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5acfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random seeds set for reproducibility ---\n",
      "\n",
      "--- Phase 1: Data Loading and Preprocessing ---\n",
      "Shape of x_train_normal (only digit '1'): (6742, 28, 28, 1)\n",
      "Shape of x_test_final (combined normal and anomaly): (10000, 28, 28, 1)\n",
      "Number of normal samples in test set: 1135\n",
      "Number of anomaly samples in test set: 8865\n",
      "\n",
      "--- Phase 2: Deep SVDD Model Development and Training ---\n",
      "\n",
      "--- Feature Extractor (CNN) Architecture Summary ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m204,928\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">223,744</span> (874.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m223,744\u001b[0m (874.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">223,744</span> (874.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m223,744\u001b[0m (874.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initializing Center 'c' using 10 batches of normal data ---\n",
      "Center 'c' initialized. Shape: (128,)\n",
      "\n",
      "--- Starting Deep SVDD Training ---\n",
      "Epoch 1/50, Loss: 0.0659\n",
      "Epoch 2/50, Loss: 0.0328\n",
      "Epoch 3/50, Loss: 0.0226\n",
      "Epoch 4/50, Loss: 0.0174\n",
      "Epoch 5/50, Loss: 0.0141\n",
      "Epoch 6/50, Loss: 0.0118\n",
      "Epoch 7/50, Loss: 0.0101\n",
      "Epoch 8/50, Loss: 0.0087\n",
      "Epoch 9/50, Loss: 0.0076\n",
      "Epoch 10/50, Loss: 0.0067\n",
      "Epoch 11/50, Loss: 0.0060\n",
      "Epoch 12/50, Loss: 0.0054\n",
      "Epoch 13/50, Loss: 0.0049\n",
      "Epoch 14/50, Loss: 0.0044\n",
      "Epoch 15/50, Loss: 0.0041\n",
      "Epoch 16/50, Loss: 0.0037\n",
      "Epoch 17/50, Loss: 0.0035\n",
      "Epoch 18/50, Loss: 0.0032\n",
      "Epoch 19/50, Loss: 0.0030\n",
      "Epoch 20/50, Loss: 0.0028\n",
      "Epoch 21/50, Loss: 0.0027\n",
      "Epoch 22/50, Loss: 0.0025\n",
      "Epoch 23/50, Loss: 0.0024\n",
      "Epoch 24/50, Loss: 0.0023\n",
      "Epoch 25/50, Loss: 0.0022\n",
      "Epoch 26/50, Loss: 0.0021\n",
      "Epoch 27/50, Loss: 0.0020\n",
      "Epoch 28/50, Loss: 0.0019\n",
      "Early stopping triggered: Average epoch loss 0.0019 is below threshold 0.0020\n",
      "--- Deep SVDD Training Complete ---\n",
      "\n",
      "--- Phase 3: Deep SVDD Anomaly Scoring and Evaluation ---\n",
      "Calculated anomaly scores for 10000 test samples.\n",
      "Min Deep SVDD anomaly score (test): 0.0006\n",
      "Max Deep SVDD anomaly score (test): 0.0244\n",
      "Mean Deep SVDD anomaly score (test): 0.0072\n",
      "Median Deep SVDD anomaly score (test): 0.0072\n",
      "\n",
      "Deep SVDD ROC AUC Score: 0.9975\n",
      "\n",
      "--- Calculating Deep SVDD Threshold from Normal Training Data Only ---\n",
      "Min Deep SVDD anomaly score (normal train): 0.0005\n",
      "Max Deep SVDD anomaly score (normal train): 0.0130\n",
      "Deep SVDD Threshold (99th percentile of NORMAL TRAINING scores): 0.0053\n",
      "\n",
      "Deep SVDD Classification Metrics (using threshold 0.0053 from normal training data):\n",
      "  Accuracy: 0.8715\n",
      "  Precision: 0.9993\n",
      "  Recall: 0.8556\n",
      "  F1-Score: 0.9219\n",
      "\n",
      "--- Phase 4: Comparison with Traditional Methods ---\n",
      "\n",
      "Shape of flattened training data for traditional methods: (6742, 784)\n",
      "Shape of flattened test data for traditional methods: (10000, 784)\n",
      "\n",
      "--- Training and Evaluating One-Class SVM ---\n",
      "One-Class SVM ROC AUC Score: 0.9971\n",
      "\n",
      "--- Training and Evaluating Isolation Forest ---\n",
      "Isolation Forest ROC AUC Score: 0.9929\n",
      "\n",
      "--- Anomaly Detection Performance Comparison (ROC AUC) ---\n",
      "Deep SVDD (Custom CNN):         0.9975\n",
      "One-Class SVM:                  0.9971\n",
      "Isolation Forest:               0.9929\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Set Random Seeds for Reproducibility ---\n",
    "# Setting seeds for Python's hash randomization, standard random module, NumPy, and TensorFlow.\n",
    "os.environ['PYTHONHASHSEED'] = str(0)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "print(\"--- Random seeds set for reproducibility ---\")\n",
    "\n",
    "# --- Global Model Parameters ---\n",
    "INPUT_SHAPE = (28, 28, 1)\n",
    "EMBEDDING_DIM = 128 # The size of our feature vector (output of Deep SVDD's CNN)\n",
    "NORMAL_CLASS = 1    # The digit '1' is considered the normal class\n",
    "LAMBDA = 1e-6       # Regularization parameter for weight decay in Deep SVDD\n",
    "LEARNING_RATE = 1e-2 # Learning rate for SGD optimizer\n",
    "EPOCHS = 50         # Maximum number of training epochs for Deep SVDD\n",
    "BATCH_SIZE = 128    # Batch size for training and inference\n",
    "\n",
    "# --- NEW GLOBAL VARIABLE for Early Stopping ---\n",
    "EARLY_STOPPING_LOSS_THRESHOLD = 0.002 # Stop training if average epoch loss falls below this value\n",
    "                                     # This value might need tuning based on observed loss convergence.\n",
    "                                     # For the given training output, a value like 0.002 or 0.0019 would have stopped it near the end.\n",
    "\n",
    "\n",
    "# --- Phase 1: Data Loading and Preprocessing ---\n",
    "print(\"\\n--- Phase 1: Data Loading and Preprocessing ---\")\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train_raw, y_train_raw), (x_test_raw, y_test_raw) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1] (convert to float32 first)\n",
    "x_train_normalized = x_train_raw.astype('float32') / 255.0\n",
    "x_test_normalized = x_test_raw.astype('float32') / 255.0\n",
    "\n",
    "# Add a channel dimension for grayscale images (for CNN input)\n",
    "x_train_processed = np.expand_dims(x_train_normalized, axis=-1)\n",
    "x_test_processed = np.expand_dims(x_test_normalized, axis=-1)\n",
    "\n",
    "# Define 'NORMAL_CLASS' (digit '1') and restructure datasets\n",
    "x_train_normal = x_train_processed[y_train_raw == NORMAL_CLASS]\n",
    "print(f\"Shape of x_train_normal (only digit '{NORMAL_CLASS}'): {x_train_normal.shape}\")\n",
    "\n",
    "x_test_normal_samples = x_test_processed[y_test_raw == NORMAL_CLASS]\n",
    "x_test_anomaly_samples = x_test_processed[y_test_raw != NORMAL_CLASS]\n",
    "\n",
    "x_test_combined = np.concatenate((x_test_normal_samples, x_test_anomaly_samples), axis=0)\n",
    "y_test_combined_labels = np.concatenate((\n",
    "    np.zeros(len(x_test_normal_samples)),\n",
    "    np.ones(len(x_test_anomaly_samples))\n",
    "), axis=0)\n",
    "\n",
    "permutation = np.random.permutation(len(x_test_combined))\n",
    "x_test_final = x_test_combined[permutation]\n",
    "y_test_final = y_test_combined_labels[permutation]\n",
    "\n",
    "print(f\"Shape of x_test_final (combined normal and anomaly): {x_test_final.shape}\")\n",
    "print(f\"Number of normal samples in test set: {np.sum(y_test_final == 0)}\")\n",
    "print(f\"Number of anomaly samples in test set: {np.sum(y_test_final == 1)}\")\n",
    "\n",
    "\n",
    "# --- Phase 2: Deep SVDD Model Development and Training ---\n",
    "print(\"\\n--- Phase 2: Deep SVDD Model Development and Training ---\")\n",
    "\n",
    "# 1. Define the CNN Architecture (Feature Extractor phi(x;W))\n",
    "def build_cnn_feature_extractor(input_shape, embedding_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(embedding_dim)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "feature_extractor = build_cnn_feature_extractor(INPUT_SHAPE, EMBEDDING_DIM)\n",
    "print(\"\\n--- Feature Extractor (CNN) Architecture Summary ---\")\n",
    "feature_extractor.summary()\n",
    "\n",
    "# 2. Define the Deep SVDD Loss Function\n",
    "@tf.function\n",
    "def deep_svdd_loss(phi_output, center, lambda_val, model_weights):\n",
    "    distance_loss = tf.reduce_mean(tf.reduce_sum(tf.square(phi_output - center), axis=1))\n",
    "    regularization_loss = 0.0\n",
    "    for weight in model_weights:\n",
    "        regularization_loss += tf.reduce_sum(tf.square(weight))\n",
    "    total_loss = distance_loss + 2 * lambda_val * regularization_loss\n",
    "    return total_loss\n",
    "\n",
    "# 3. Data-Dependent Fixed Center 'c' Initialization\n",
    "def initialize_center(model, normal_data, num_batches_for_init=10, batch_size=BATCH_SIZE):\n",
    "    print(f\"\\n--- Initializing Center 'c' using {num_batches_for_init} batches of normal data ---\")\n",
    "    features_sum = tf.zeros(model.output_shape[-1], dtype=tf.float32)\n",
    "    num_samples = 0\n",
    "    normal_dataset = tf.data.Dataset.from_tensor_slices(normal_data).batch(batch_size)\n",
    "    for i, batch in enumerate(normal_dataset):\n",
    "        if i >= num_batches_for_init:\n",
    "            break\n",
    "        embeddings = model(batch, training=False)\n",
    "        features_sum += tf.reduce_sum(embeddings, axis=0)\n",
    "        num_samples += batch.shape[0]\n",
    "    center_c = features_sum / num_samples\n",
    "    print(f\"Center 'c' initialized. Shape: {center_c.shape}\")\n",
    "    return center_c\n",
    "\n",
    "center = initialize_center(feature_extractor, x_train_normal)\n",
    "\n",
    "# 4. Training Loop Implementation\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train_normal).shuffle(\n",
    "    buffer_size=len(x_train_normal)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"\\n--- Starting Deep SVDD Training ---\")\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, current_center):\n",
    "    with tf.GradientTape() as tape:\n",
    "        phi_output = feature_extractor(images, training=True)\n",
    "        loss = deep_svdd_loss(phi_output, current_center, LAMBDA, feature_extractor.trainable_weights)\n",
    "    gradients = tape.gradient(loss, feature_extractor.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, feature_extractor.trainable_weights))\n",
    "    return loss\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_epoch_loss = 0\n",
    "    num_batches = 0\n",
    "    for batch_images in train_dataset:\n",
    "        loss = train_step(batch_images, center)\n",
    "        total_epoch_loss += loss.numpy()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_epoch_loss = total_epoch_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "    # --- Early Stopping Check ---\n",
    "    if avg_epoch_loss < EARLY_STOPPING_LOSS_THRESHOLD:\n",
    "        print(f\"Early stopping triggered: Average epoch loss {avg_epoch_loss:.4f} is below threshold {EARLY_STOPPING_LOSS_THRESHOLD:.4f}\")\n",
    "        break # Exit the training loop\n",
    "\n",
    "print(\"--- Deep SVDD Training Complete ---\")\n",
    "\n",
    "\n",
    "# --- Phase 3: Deep SVDD Anomaly Scoring and Evaluation ---\n",
    "print(\"\\n--- Phase 3: Deep SVDD Anomaly Scoring and Evaluation ---\")\n",
    "\n",
    "# 1. Calculate Anomaly Scores for the Test Dataset\n",
    "test_dataset_inference = tf.data.Dataset.from_tensor_slices(x_test_final).batch(BATCH_SIZE)\n",
    "all_test_embeddings = []\n",
    "for batch_images in test_dataset_inference:\n",
    "    embeddings = feature_extractor(batch_images, training=False)\n",
    "    all_test_embeddings.append(embeddings)\n",
    "\n",
    "all_test_embeddings = tf.concat(all_test_embeddings, axis=0)\n",
    "deep_svdd_anomaly_scores = tf.reduce_sum(tf.square(all_test_embeddings - center), axis=1).numpy()\n",
    "\n",
    "print(f\"Calculated anomaly scores for {len(deep_svdd_anomaly_scores)} test samples.\")\n",
    "print(f\"Min Deep SVDD anomaly score (test): {np.min(deep_svdd_anomaly_scores):.4f}\")\n",
    "print(f\"Max Deep SVDD anomaly score (test): {np.max(deep_svdd_anomaly_scores):.4f}\")\n",
    "print(f\"Mean Deep SVDD anomaly score (test): {np.mean(deep_svdd_anomaly_scores):.4f}\")\n",
    "print(f\"Median Deep SVDD anomaly score (test): {np.median(deep_svdd_anomaly_scores):.4f}\")\n",
    "\n",
    "# 2. Evaluate using ROC AUC\n",
    "roc_auc_deep_svdd = roc_auc_score(y_test_final, deep_svdd_anomaly_scores)\n",
    "print(f\"\\nDeep SVDD ROC AUC Score: {roc_auc_deep_svdd:.4f}\")\n",
    "\n",
    "\n",
    "# 3. Calculate Threshold from NORMAL TRAINING DATA ONLY (e.g., 99th percentile)\n",
    "print(\"\\n--- Calculating Deep SVDD Threshold from Normal Training Data Only ---\")\n",
    "\n",
    "normal_train_dataset_inference = tf.data.Dataset.from_tensor_slices(x_train_normal).batch(BATCH_SIZE)\n",
    "normal_train_embeddings = []\n",
    "for batch_images in normal_train_dataset_inference:\n",
    "    embeddings = feature_extractor(batch_images, training=False)\n",
    "    normal_train_embeddings.append(embeddings)\n",
    "normal_train_embeddings = tf.concat(normal_train_embeddings, axis=0)\n",
    "\n",
    "deep_svdd_normal_train_scores = tf.reduce_sum(tf.square(normal_train_embeddings - center), axis=1).numpy()\n",
    "\n",
    "threshold_deep_svdd = np.percentile(deep_svdd_normal_train_scores, 99)\n",
    "\n",
    "print(f\"Min Deep SVDD anomaly score (normal train): {np.min(deep_svdd_normal_train_scores):.4f}\")\n",
    "print(f\"Max Deep SVDD anomaly score (normal train): {np.max(deep_svdd_normal_train_scores):.4f}\")\n",
    "print(f\"Deep SVDD Threshold (99th percentile of NORMAL TRAINING scores): {threshold_deep_svdd:.4f}\")\n",
    "\n",
    "\n",
    "# 4. Classify test samples based on the new threshold\n",
    "y_pred_deep_svdd_binary = (deep_svdd_anomaly_scores > threshold_deep_svdd).astype(int)\n",
    "\n",
    "# 5. Report classification metrics using this threshold\n",
    "acc_deep_svdd = accuracy_score(y_test_final, y_pred_deep_svdd_binary)\n",
    "prec_deep_svdd = precision_score(y_test_final, y_pred_deep_svdd_binary)\n",
    "rec_deep_svdd = recall_score(y_test_final, y_pred_deep_svdd_binary)\n",
    "f1_deep_svdd = f1_score(y_test_final, y_pred_deep_svdd_binary)\n",
    "\n",
    "print(f\"\\nDeep SVDD Classification Metrics (using threshold {threshold_deep_svdd:.4f} from normal training data):\")\n",
    "print(f\"  Accuracy: {acc_deep_svdd:.4f}\")\n",
    "print(f\"  Precision: {prec_deep_svdd:.4f}\")\n",
    "print(f\"  Recall: {rec_deep_svdd:.4f}\")\n",
    "print(f\"  F1-Score: {f1_deep_svdd:.4f}\")\n",
    "\n",
    "\n",
    "# --- Phase 4: Comparison with Traditional Methods ---\n",
    "print(\"\\n--- Phase 4: Comparison with Traditional Methods ---\")\n",
    "\n",
    "# Data preparation for traditional methods: Flatten images\n",
    "x_train_flat = x_train_normal.reshape(x_train_normal.shape[0], -1)\n",
    "x_test_flat = x_test_final.reshape(x_test_final.shape[0], -1)\n",
    "\n",
    "print(f\"\\nShape of flattened training data for traditional methods: {x_train_flat.shape}\")\n",
    "print(f\"Shape of flattened test data for traditional methods: {x_test_flat.shape}\")\n",
    "\n",
    "\n",
    "# 1. One-Class SVM (OC-SVM)\n",
    "print(\"\\n--- Training and Evaluating One-Class SVM ---\")\n",
    "oc_svm = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma='scale')\n",
    "oc_svm.fit(x_train_flat)\n",
    "oc_svm_anomaly_scores = -oc_svm.decision_function(x_test_flat)\n",
    "roc_auc_oc_svm = roc_auc_score(y_test_final, oc_svm_anomaly_scores)\n",
    "print(f\"One-Class SVM ROC AUC Score: {roc_auc_oc_svm:.4f}\")\n",
    "\n",
    "\n",
    "# 2. Isolation Forest (IF)\n",
    "print(\"\\n--- Training and Evaluating Isolation Forest ---\")\n",
    "isolation_forest = IsolationForest(random_state=42, contamination='auto')\n",
    "isolation_forest.fit(x_train_flat)\n",
    "isolation_forest_anomaly_scores = -isolation_forest.decision_function(x_test_flat)\n",
    "roc_auc_isolation_forest = roc_auc_score(y_test_final, isolation_forest_anomaly_scores)\n",
    "print(f\"Isolation Forest ROC AUC Score: {roc_auc_isolation_forest:.4f}\")\n",
    "\n",
    "\n",
    "# --- Final Performance Comparison Summary (ROC AUC) ---\n",
    "print(\"\\n--- Anomaly Detection Performance Comparison (ROC AUC) ---\")\n",
    "print(f\"Deep SVDD (Custom CNN):         {roc_auc_deep_svdd:.4f}\")\n",
    "print(f\"One-Class SVM:                  {roc_auc_oc_svm:.4f}\")\n",
    "print(f\"Isolation Forest:               {roc_auc_isolation_forest:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
